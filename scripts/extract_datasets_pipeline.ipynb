{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract BioProject datasets pipeline\n",
    "\n",
    "This notebook restores the original interactive pipeline helpers for querying NCBI BioProject and SRA metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T20:23:12.826416900Z",
     "start_time": "2025-11-06T20:23:12.772220300Z"
    }
   },
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\"\"\"Utilities for extracting BioProject datasets from NCBI.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Sequence\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"BIOPROJECT_QUERY_DEFAULT\",\n",
    "    \"fetch_bioproject_details\",\n",
    "    \"fetch_srr_details\",\n",
    "    \"load_bioproject_table\",\n",
    "    \"map_bioproject_to_biosample\",\n",
    "    \"map_bioproject_to_srr\",\n",
    "    \"run_pipeline\",\n",
    "    \"search_bioprojects\",\n",
    "    \"setup_entrez\",\n",
    "    \"summarize_samples\",\n",
    "    \"write_bioproject_srr_mapping\",\n",
    "    \"write_bioproject_table\",\n",
    "]\n",
    "\n",
    "\n",
    "BIOPROJECT_QUERY_DEFAULT = '(\"Exaiptasia diaphana\"[Organism] AND microbiome)'\n",
    "\n",
    "\n",
    "def setup_entrez(email: str) -> None:\n",
    "    \"\"\"Configure the Entrez client with a contact email address.\"\"\"\n",
    "\n",
    "    Entrez.email = email\n",
    "\n",
    "\n",
    "def search_bioprojects(query: str, retmax: int = 100) -> Dict:\n",
    "    \"\"\"Run an Entrez search against the BioProject database.\"\"\"\n",
    "\n",
    "    handle = Entrez.esearch(db=\"bioproject\", term=query, retmax=retmax)\n",
    "    try:\n",
    "        return Entrez.read(handle)\n",
    "    finally:\n",
    "        handle.close()\n",
    "\n",
    "\n",
    "def fetch_bioproject_details(id_list: Sequence[str]) -> List[Dict]:\n",
    "    \"\"\"Fetch metadata for a sequence of BioProject identifiers.\"\"\"\n",
    "\n",
    "    if not id_list:\n",
    "        return []\n",
    "\n",
    "    handle = Entrez.efetch(\n",
    "        db=\"bioproject\",\n",
    "        id=\",\".join(id_list),\n",
    "        rettype=\"docsum\",\n",
    "        retmode=\"xml\",\n",
    "    )\n",
    "    try:\n",
    "        document = Entrez.read(handle)[\"DocumentSummarySet\"][\"DocumentSummary\"]\n",
    "    finally:\n",
    "        handle.close()\n",
    "    return document\n",
    "\n",
    "\n",
    "def write_bioproject_table(projects: Iterable[Dict], path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Write BioProject metadata to a TSV file and return it as a DataFrame.\"\"\"\n",
    "\n",
    "    columns = [\n",
    "        \"ProjectId\",\n",
    "        \"ProjectAcc\",\n",
    "        \"ProjectDate\",\n",
    "        \"ProjectTitle\",\n",
    "        \"ProjectDescription\",\n",
    "        \"OrganismName\",\n",
    "        \"OrganismStrain\",\n",
    "    ]\n",
    "    records = []\n",
    "    for project in projects:\n",
    "        records.append(\n",
    "            {\n",
    "                \"ProjectId\": project.get(\"Project_Id\", \"\"),\n",
    "                \"ProjectAcc\": project.get(\"Project_Acc\", \"\"),\n",
    "                \"ProjectDate\": project.get(\"Registration_Date\", \"\"),\n",
    "                \"ProjectTitle\": project.get(\"Project_Title\", \"\"),\n",
    "                \"ProjectDescription\": project.get(\"Project_Description\", \"\"),\n",
    "                \"OrganismName\": project.get(\"Organism_Name\", \"\"),\n",
    "                \"OrganismStrain\": project.get(\"Organism_Strain\", \"\"),\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(records, columns=columns)\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, sep=\"\\t\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_bioproject_table(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a BioProject table that was previously written to disk.\"\"\"\n",
    "\n",
    "    return pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "\n",
    "def map_bioproject_to_biosample(project_ids: Iterable[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Map BioProject identifiers to linked BioSample accessions.\"\"\"\n",
    "\n",
    "    mapping: Dict[str, List[str]] = {}\n",
    "    for proj in project_ids:\n",
    "        link = Entrez.elink(dbfrom=\"bioproject\", db=\"biosample\", id=str(proj))\n",
    "        try:\n",
    "            link_results = Entrez.read(link)\n",
    "        finally:\n",
    "            link.close()\n",
    "        biosample_ids: List[str] = []\n",
    "        for link_set in link_results:\n",
    "            if \"LinkSetDb\" not in link_set:\n",
    "                continue\n",
    "            for link_db in link_set[\"LinkSetDb\"]:\n",
    "                if link_db.get(\"DbTo\") != \"biosample\":\n",
    "                    continue\n",
    "                for link_entry in link_db.get(\"Link\", []):\n",
    "                    link_id = str(link_entry[\"Id\"])\n",
    "                    if link_id not in biosample_ids:\n",
    "                        biosample_ids.append(link_id)\n",
    "        mapping[str(proj)] = biosample_ids\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def map_bioproject_to_srr(project_ids: Iterable[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Map BioProject identifiers to linked SRA run accessions.\"\"\"\n",
    "\n",
    "    mapping: Dict[str, List[str]] = {}\n",
    "    for project_id in project_ids:\n",
    "        link = Entrez.elink(dbfrom=\"bioproject\", db=\"sra\", id=str(project_id))\n",
    "        try:\n",
    "            link_results = Entrez.read(link)\n",
    "        finally:\n",
    "            link.close()\n",
    "        link_list: List[str] = []\n",
    "        for link_set in link_results:\n",
    "            if \"LinkSetDb\" not in link_set:\n",
    "                continue\n",
    "            for subset in link_set[\"LinkSetDb\"]:\n",
    "                if subset.get(\"DbTo\") != \"sra\":\n",
    "                    continue\n",
    "                for entry in subset.get(\"Link\", []):\n",
    "                    new_sra_id = str(entry[\"Id\"])\n",
    "                    if new_sra_id not in link_list:\n",
    "                        link_list.append(new_sra_id)\n",
    "        mapping[str(project_id)] = link_list\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def write_bioproject_srr_mapping(\n",
    "    mapping: Dict[str, List[str]], path: Path\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Persist the BioProject-to-SRR mapping to disk.\"\"\"\n",
    "\n",
    "    records = []\n",
    "    for project_id, srr_ids in mapping.items():\n",
    "        for srr_id in srr_ids:\n",
    "            records.append({\"BioProject\": project_id, \"SRR\": srr_id})\n",
    "    df = pd.DataFrame(records, columns=[\"BioProject\", \"SRR\"])\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, sep=\"\\t\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _parse_library_layout(lib_descriptor: ET.Element | None) -> str:\n",
    "    if lib_descriptor is None:\n",
    "        return \"\"\n",
    "    layout_elem = lib_descriptor.find(\"LIBRARY_LAYOUT\")\n",
    "    if layout_elem is None or not len(layout_elem):\n",
    "        return \"\"\n",
    "    return layout_elem[0].tag\n",
    "\n",
    "\n",
    "def fetch_srr_details(mapping: Dict[str, List[str]], path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Fetch SRR metadata for each BioProject and store it as a TSV file.\"\"\"\n",
    "\n",
    "    header = [\n",
    "        \"BioProjectId\",\n",
    "        \"Title\",\n",
    "        \"Platform\",\n",
    "        \"Instrument\",\n",
    "        \"Runs\",\n",
    "        \"Spots\",\n",
    "        \"Bases\",\n",
    "        \"Submitter\",\n",
    "        \"Experiment\",\n",
    "        \"Study\",\n",
    "        \"Organism\",\n",
    "        \"Sample\",\n",
    "        \"Library\",\n",
    "        \"Strategy\",\n",
    "        \"Source\",\n",
    "        \"Layout\",\n",
    "        \"Bioproject\",\n",
    "        \"Biosample\",\n",
    "    ]\n",
    "    rows = []\n",
    "    for bioproject, srr_ids in mapping.items():\n",
    "        if not srr_ids:\n",
    "            continue\n",
    "        fetch = Entrez.esummary(db=\"sra\", id=\",\".join(srr_ids), rettype=\"text\")\n",
    "        try:\n",
    "            summaries = Entrez.read(fetch)\n",
    "        finally:\n",
    "            fetch.close()\n",
    "        for summary in summaries:\n",
    "            xml_string = \"<root>\" + summary[\"ExpXml\"] + \"</root>\"\n",
    "            root = ET.fromstring(xml_string)\n",
    "            summ = root.find(\"Summary\")\n",
    "            if summ is not None:\n",
    "                title = summ.findtext(\"Title\", default=\"\")\n",
    "                platform = summ.findtext(\"Platform\", default=\"\")\n",
    "                platform_elem = summ.find(\"Platform\")\n",
    "                instrument_model = (\n",
    "                    platform_elem.attrib.get(\"instrument_model\", \"\")\n",
    "                    if platform_elem is not None\n",
    "                    else \"\"\n",
    "                )\n",
    "                stats_elem = summ.find(\"Statistics\")\n",
    "                if stats_elem is not None:\n",
    "                    total_runs = stats_elem.attrib.get(\"total_runs\", \"\")\n",
    "                    total_spots = stats_elem.attrib.get(\"total_spots\", \"\")\n",
    "                    total_bases = stats_elem.attrib.get(\"total_bases\", \"\")\n",
    "                else:\n",
    "                    total_runs = total_spots = total_bases = \"\"\n",
    "            else:\n",
    "                title = platform = instrument_model = \"\"\n",
    "                total_runs = total_spots = total_bases = \"\"\n",
    "            submitter = root.find(\"Submitter\")\n",
    "            submitter_acc = submitter.attrib.get(\"acc\", \"\") if submitter is not None else \"\"\n",
    "            experiment = root.find(\"Experiment\")\n",
    "            experiment_acc = (\n",
    "                experiment.attrib.get(\"acc\", \"\") if experiment is not None else \"\"\n",
    "            )\n",
    "            study = root.find(\"Study\")\n",
    "            study_acc = study.attrib.get(\"acc\", \"\") if study is not None else \"\"\n",
    "            organism = root.find(\"Organism\")\n",
    "            organism_name = (\n",
    "                organism.attrib.get(\"ScientificName\", \"\") if organism is not None else \"\"\n",
    "            )\n",
    "            sample = root.find(\"Sample\")\n",
    "            sample_acc = sample.attrib.get(\"acc\", \"\") if sample is not None else \"\"\n",
    "            lib_descriptor = root.find(\"Library_descriptor\")\n",
    "            if lib_descriptor is not None:\n",
    "                library_name = lib_descriptor.findtext(\"LIBRARY_NAME\", default=\"\")\n",
    "                library_strategy = lib_descriptor.findtext(\"LIBRARY_STRATEGY\", default=\"\")\n",
    "                library_source = lib_descriptor.findtext(\"LIBRARY_SOURCE\", default=\"\")\n",
    "                library_layout = _parse_library_layout(lib_descriptor)\n",
    "            else:\n",
    "                library_name = library_strategy = library_source = \"\"\n",
    "                library_layout = \"\"\n",
    "            bioproject_acc = root.findtext(\"Bioproject\", default=\"\")\n",
    "            biosample_acc = root.findtext(\"Biosample\", default=\"\")\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"BioProjectId\": bioproject,\n",
    "                    \"Title\": title,\n",
    "                    \"Platform\": platform,\n",
    "                    \"Instrument\": instrument_model,\n",
    "                    \"Runs\": total_runs,\n",
    "                    \"Spots\": total_spots,\n",
    "                    \"Bases\": total_bases,\n",
    "                    \"Submitter\": submitter_acc,\n",
    "                    \"Experiment\": experiment_acc,\n",
    "                    \"Study\": study_acc,\n",
    "                    \"Organism\": organism_name,\n",
    "                    \"Sample\": sample_acc,\n",
    "                    \"Library\": library_name,\n",
    "                    \"Strategy\": library_strategy,\n",
    "                    \"Source\": library_source,\n",
    "                    \"Layout\": library_layout,\n",
    "                    \"Bioproject\": bioproject_acc,\n",
    "                    \"Biosample\": biosample_acc,\n",
    "                }\n",
    "            )\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, sep=\"\\t\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize_samples(srr_table: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Return a summary Series counting SRR entries per BioProject.\"\"\"\n",
    "\n",
    "    if \"BioProjectId\" not in srr_table.columns:\n",
    "        raise ValueError(\"SRR table must contain a 'BioProjectId' column\")\n",
    "    return srr_table.groupby(\"BioProjectId\").size()\n",
    "\n",
    "\n",
    "def run_pipeline(\n",
    "    email: str,\n",
    "    output_dir: Path,\n",
    "    query: str = BIOPROJECT_QUERY_DEFAULT,\n",
    "    retmax: int = 100,\n",
    ") -> Dict[str, pd.DataFrame | pd.Series | Dict[str, List[str]]]:\n",
    "    \"\"\"Execute the full extraction pipeline and return intermediate results.\"\"\"\n",
    "\n",
    "    setup_entrez(email)\n",
    "    search_results = search_bioprojects(query=query, retmax=retmax)\n",
    "    ids = search_results.get(\"IdList\", [])\n",
    "    projects = fetch_bioproject_details(ids)\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    bioproject_table_path = output_dir / \"bioproject_table.tsv\"\n",
    "    bioproject_df = write_bioproject_table(projects, bioproject_table_path)\n",
    "\n",
    "    bioproject_ids = bioproject_df[\"ProjectId\"].astype(str).tolist()\n",
    "    bioproject_to_biosample = map_bioproject_to_biosample(bioproject_ids)\n",
    "    bioproject_to_srr = map_bioproject_to_srr(bioproject_ids)\n",
    "\n",
    "    srr_map_path = output_dir / \"bioproject_srr_table.tsv\"\n",
    "    bioproject_srr_df = write_bioproject_srr_mapping(bioproject_to_srr, srr_map_path)\n",
    "\n",
    "    srr_details_path = output_dir / \"bioproject_srr_details.tsv\"\n",
    "    srr_table = fetch_srr_details(bioproject_to_srr, srr_details_path)\n",
    "    sample_summary = summarize_samples(srr_table)\n",
    "\n",
    "    return {\n",
    "        \"search_results\": search_results,\n",
    "        \"bioproject_df\": bioproject_df,\n",
    "        \"bioproject_to_biosample\": bioproject_to_biosample,\n",
    "        \"bioproject_to_srr\": bioproject_to_srr,\n",
    "        \"bioproject_srr_df\": bioproject_srr_df,\n",
    "        \"srr_table\": srr_table,\n",
    "        \"sample_summary\": sample_summary,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example execution\n",
    "\n",
    "Uncomment the call below to run the pipeline with your email and output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T20:12:33.776998800Z",
     "start_time": "2025-11-06T20:12:07.743106200Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "BioProjectId\n1089063       2\n1336731      40\n360672        6\n524291       58\n576020     1510\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_pipeline(\n",
    "     email=\"lukas.becker@hhu.de\",\n",
    "     output_dir=Path(\"../data\"),\n",
    " )\n",
    "results[\"sample_summary\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['search_results', 'bioproject_df', 'bioproject_to_biosample', 'bioproject_to_srr', 'bioproject_srr_df', 'srr_table', 'sample_summary'])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T20:14:21.193953200Z",
     "start_time": "2025-11-06T20:14:21.191954500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Count': '12', 'RetMax': '12', 'RetStart': '0', 'IdList': ['1336731', '1089063', '988282', '907389', '650220', '630329', '592182', '588472', '576556', '576020', '524291', '360672'], 'TranslationSet': [], 'TranslationStack': [{'Term': '\"Exaiptasia diaphana\"[Organism]', 'Field': 'Organism', 'Count': '47', 'Explode': 'Y'}, {'Term': 'microbiome[All Fields]', 'Field': 'All Fields', 'Count': '27521', 'Explode': 'N'}, 'AND', 'GROUP'], 'QueryTranslation': '\"Exaiptasia diaphana\"[Organism] AND microbiome[All Fields]'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"search_results\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T20:16:54.849409500Z",
     "start_time": "2025-11-06T20:16:54.800484100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
